<!DOCTYPE html><html lang="en-US" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>1. Kafka | Yuchen You</title><meta name="author" content="Yuchen You (Wesley)"><meta name="copyright" content="Yuchen You (Wesley)"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Introduction Event Streaming the practice of capturing data in real-time from event sources like databases, sensors, mobile devices, cloud services, and software applications in the form of streams of">
<meta property="og:type" content="article">
<meta property="og:title" content="1. Kafka">
<meta property="og:url" content="http://example.com/2025/05/07/wesley_knowledge_repo/os/Apache/1.%20Kafka/index.html">
<meta property="og:site_name" content="Yuchen You">
<meta property="og:description" content="Introduction Event Streaming the practice of capturing data in real-time from event sources like databases, sensors, mobile devices, cloud services, and software applications in the form of streams of">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/me_new.jpeg">
<meta property="article:published_time" content="2025-05-07T16:16:12.000Z">
<meta property="article:modified_time" content="2025-05-11T21:23:01.191Z">
<meta property="article:author" content="Yuchen You (Wesley)">
<meta property="article:tag" content="distributed_sys">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/me_new.jpeg"><link rel="shortcut icon" href="/img/hackerrank.svg"><link rel="canonical" href="http://example.com/2025/05/07/wesley_knowledge_repo/os/Apache/1.%20Kafka/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '1. Kafka',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-05-12 05:23:01'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/me_new.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">293</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/math_master.jpeg')"><nav id="nav"><span id="blog-info"><a href="/" title="Yuchen You"><img class="site-icon" src="/img/avatar.png"/><span class="site-name">Yuchen You</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">1. Kafka</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-05-07T16:16:12.000Z" title="Created 2025-05-08 00:16:12">2025-05-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-05-11T21:23:01.191Z" title="Updated 2025-05-12 05:23:01">2025-05-12</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="1. Kafka"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="introduction">Introduction</h2>
<h3 id="event-streaming">Event Streaming</h3>
<p>the practice of capturing data in real-time from event sources like databases, sensors, mobile devices, cloud services, and software applications in the form of streams of events</p>
<p>routing the event streams to different destination technologies as needed</p>
<p>ensures a continuous flow and interpretation of data so that the right information is at the right place, at the right time</p>
<h3 id="kafka-s-event-stream-purpose">Kafka’s Event Stream Purpose</h3>
<ol>
<li>To <strong>publish (write)</strong> and <strong>subscribe to (read)</strong> streams of events, including continuous import/export of your data from other systems.</li>
<li>To <strong>store</strong> streams of events <strong>durably</strong> and <strong>reliably</strong> for as long as you want.</li>
<li>To <strong>process</strong> streams of events as they <strong>occur</strong> (RT) or<br>
<strong>retrospectively</strong>.</li>
</ol>
<h3 id="server-and-client-in-kafka">Server and Client in Kafka</h3>
<p>Kafka’s server and client communicate to each other via <strong>TCP</strong> protocol</p>
<h4 id="server">Server</h4>
<ul>
<li>run as a cluster of one or more servers that can span multiple datacenters or cloud regions</li>
<li><strong>Brokers</strong>: servers that form the storage layer (Cache Proxy)</li>
<li>Other servers run Kafka Connect to <em>continuously import and export</em> data as <em>event streams</em> to integrate Kafka with your existing systems such as relational databases as well as other Kafka clusters</li>
<li><strong>Fault-Tolerance</strong>: if any of its servers fails, the other servers will take over their work to ensure continuous operations without any data loss.</li>
</ul>
<h4 id="client">Client</h4>
<ul>
<li>write distributed applications and microservices that read, write, and process streams of events in parallel, at scale, and in a fault-tolerant manner even in the case of network problems or machine failures</li>
</ul>
<h3 id="定义">定义</h3>
<ul>
<li><strong>Event</strong>: records the fact that “something happened” in the world or in your<br>
business. <code>read</code>, <code>write</code> any data from a distributed system is a form of event.
<ul>
<li>example as follow</li>
</ul>
</li>
</ul>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Event key: &quot;Alice&quot;</span><br><span class="line">Event value: &quot;Made a payment of $200 to Bob&quot;</span><br><span class="line">Event timestamp: &quot;Jun. 25, 2020 at 2:06 p.m.&quot;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Producer</strong>: <strong>client</strong>, <strong>publish</strong> events to Kafka</li>
<li><strong>Consumer (subscriber)</strong>: subscribe to (<strong>read and process</strong>) these events
<ul>
<li>producers and consumers are fully decoupled agnostic of each other.</li>
<li>producers never need to wait for consumers</li>
<li>Kafka provides guarantees to process events <em><strong>exactly-once</strong></em> (remember<br>
from eecs482 distributed system class, we have client at-least-once, server<br>
at-most-once, but adding these 2 together plus some fault tolerance tricks can<br>
make it “exactly-once”)</li>
</ul>
</li>
<li><strong>Topic</strong>: event are stored in <strong>topics</strong> organized and durable.
<ul>
<li>topic is similar to a folder in a filesystem, where files are events</li>
<li>events in a topic can be read as often as needed.
<ul>
<li>different from traditional system, where events are deleted after consumption.</li>
<li>you should <strong>define how long</strong> Kafka should retain(保持) your events<br>
(after which discard old events)</li>
</ul>
</li>
</ul>
</li>
<li><strong>Partition</strong>: a topic is spread over a number of “buckets” located on different Kafka brokers
<ul>
<li>very important for scalability: it allows client apps to read/write from/to<br>
many brokers at the same time.</li>
<li>when a event is introduced to a topic, it is actually appended to one of the<br>
topic partitions. Events with the same event key will be written to the same<br>
partition.
<ul>
<li>Kafka will guarantee that any consumer of a given topic-partition will always read that partition’s events in exactly the same order as they were written.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/kafka_concept.png" alt="kafka_concept"></p>
<ul>
<li><strong>Fault Tolerance</strong>: every topic can be replicated (even across geo-region or<br>
data centers), s.t. always be multiple brokers have a copy of data (common replication number is 3), and the replication is conducted <strong>at the granularity of topic-partition level</strong></li>
</ul>
<h3 id="应用">应用</h3>
<h4 id="messaging-消息代理">Messaging 消息代理</h4>
<p><strong>Advantage over traditional Message Brokers</strong>:</p>
<ul>
<li><strong>Decouple</strong>: producer send msg and no need to concern whom will consume it.</li>
<li><strong>Buffering</strong>: for internet flow burst, buffer some packs
<ul>
<li>High Throughput</li>
<li>Durability and Replayability</li>
</ul>
</li>
</ul>
<h4 id="website-activity-tracking">Website Activity Tracking</h4>
<p><strong>original</strong> use of Kafka was to <strong>be able to rebuild a user activity tracking pipeline as a set of real-time publish-subscribe feeds (一个有序, 可追加, 可供多个消费者订阅和消费的事件／数据流)</strong></p>
<p>site activity (page views, searches, or others) is published to central topics with one topic per activity type</p>
<h2 id="design">Design</h2>
<h3 id="motivation">Motivation</h3>
<ul>
<li>to be able to act as a unified platform for handling all the real-time data feeds <em>a large company might have</em>
<ul>
<li><strong>Requirements for large company</strong>
<ul>
<li><strong>high-throughput</strong> to support high volume event streams such as real-time log aggregation</li>
<li>deal gracefully with <strong>large data backlogs</strong> to be able to support <strong>periodic data loads</strong> from offline systems</li>
<li>handle <strong>low-latency delivery</strong> to handle more traditional messaging use-cases</li>
</ul>
</li>
</ul>
</li>
<li>support partitioned, distributed, real-time processing of these feeds to create new, derived feeds. This motivated our partitioning and consumer model.</li>
<li>guarantee fault-tolerance in the presence of machine failures</li>
</ul>
<h3 id="persistence">Persistence</h3>
<ul>
<li>
<p>Persistence storage relies on disk, which is stable but <strong>slow in performance</strong>; <strong>How to use disk properly</strong> affects the disk performance a lot.</p>
</li>
<li>
<p><strong>Key Factor about Performance</strong>: <strong>Throughput</strong>, <strong>Disk Seek Latency</strong>, and<br>
there are divergence (差错) in between.</p>
</li>
<li>
<p><strong>Linear Writes</strong>: predictable on all os, thus are <strong>optimized</strong> to <code>read-ahead</code><br>
(recall eecs482 lecture 19 file_system’s last page, for sequentially accessed<br>
files can be a big win unless file scattered across the disk) and <code>write-behind</code><br>
(recall eecs482 project 3, defer-and-avoid-work, copy-on-write strategy)</p>
</li>
<li>
<p><strong>Compensate for performance divergence</strong>: modern os became aggressive in use of RAM for disk caching.</p>
<ul>
<li>modern os divert (转移) all free memory to disk caching</li>
</ul>
</li>
</ul>
<h4 id="pagecache-页缓存-recall-memory-is-the-unified-cache-for-address-space">PageCache 页缓存 (recall memory is the unified cache for address space)</h4>
<p>Since RAM is a kind of file system’s cache, the following paragraphs will refer<br>
pagecache to memory. And similar to the cache, all read/write to filesystems<br>
will go through pagecache first. <strong>Namely the pagecache is a partition of the<br>
memory where the kernel reserves for all disk IO, while the in-memory cache is<br>
the process memory</strong>. The pagecache is maintained by the OS (recall eecs482<br>
project 3 file-backed page), and the in-memory cache is maintained by the app (process) itself (swap-backed page) -&gt; this leads to the problem of cold-start, where on start the available pages will be aggresively used to load files for pagecache, but not for the in-memory cache</p>
<p>The JVM is known for its poor memory usage on <strong>object (class) mem padding</strong>, also, it’s<br>
pretty bad in garbage collection (<strong>GC</strong>), especially for large programs. We<br>
aim to solve these 2 problems with Kafka.</p>
<p>Note: JVM’s class object will store the memory in heap of its process, which<br>
will lead to GC</p>
<p>Terminology:</p>
<ul>
<li>cold: load from nothing</li>
<li>warm: start with something in cache/memory</li>
</ul>
<h4 id="pagecache-centric">PageCache-Centric</h4>
<p>Use pagecache instead of in-memory page, namely everytime on write, we write log<br>
to the memory’s log (in the pagecache part), while the traditional methods tends<br>
to write to the disks when the RAM is full, which could become very slow.</p>
<h3 id="constant-time-suffies">Constant Time Suffies</h3>
<p>For msg system’s persistency, they use <strong>per-consumer queue with associated<br>
BTree</strong> or other generall purpose random access structure to maintain metadata about messages.<br>
The time complexity of this structure is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\log N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>, which could be <strong>quite slow</strong><br>
for disk operations, since for tree seek, if there are many memory-miss seeks,<br>
then the process will becom quite slow.</p>
<h4 id="log-structure-append-only-commit-log">Log Structure (Append-Only-Commit-Log)</h4>
<p>Get idea from the log <strong>append and sequetial read</strong> operation.</p>
<ul>
<li><strong>append for enqueue</strong>: only add to the last page, which only takes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> time</li>
<li><strong>sequential read for dequeue</strong>: only read the next page, which only takes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> time.<br>
With the above 2 designs, we could let read/write independent of each other. And<br>
the above design features sequential rw to disk.</li>
</ul>
<p><strong>Comparison with the traditional msg system</strong>: if we use filesystem’s BTree<br>
structure, then the write to the last node might influence the previous nodes<br>
(recall eecs482 p4 writing to file datablock will influence the file inode). The<br>
Append-Only-Commit-Log ensures that we only write to single blocks at last (no<br>
need to do memory-trace for the destination).</p>
<p>At the same time the performance is completely decoupled from the data size, the<br>
server could use many cheap and slow disks to store.</p>
<p>Having access to virtually unlimited disk space without any performance penalty means that we can provide some features not usually found in a messaging system.<br>
For example, we don’t need to delete the data after it is consumed immediately.</p>
<h3 id="efficiency">Efficiency</h3>
<p>After talking about problems in the disk efficiency, there are 2 remained problems:</p>
<ul>
<li><strong>too many small I/O operations</strong></li>
<li><strong>excessive byte copying</strong></li>
</ul>
<h4 id="address-the-too-many-small-io-operations-batching">Address the “Too many small IO operations”: Batching</h4>
<p>Build a <strong>Message Set</strong> abstraction that naturally groups messages together.</p>
<p><strong>Network</strong> requests <strong>group messages together</strong> and <strong>amortize the overhead of the network roundtrip</strong> rather than sending a single message at a time</p>
<p><strong>Server</strong> appends chunks of messages to its log in one go</p>
<p><strong>Consumer</strong> fetches large linear chunks at a time</p>
<p><strong>RESULT</strong>: turn a bursty stream of random message writes into linear writes that flow to the consumers</p>
<h4 id="address-the-excessive-byte-copying">Address the “Excessive byte copying”</h4>
<p><strong>What is Byte Copy?</strong> it’s just like that you send some data over the network,<br>
where the data from local byte to the network binary bytes, and upon receiving,<br>
it will also turn into the end host’s system order.</p>
<p><strong>Solution</strong>: share a unified data structure among Producer, Consumer, Broker.</p>
<p><strong>Traditional process of data sending</strong>:</p>
<ol>
<li>The operating system reads data from the disk into pagecache in kernel space</li>
<li>The application reads the data from kernel space into a user-space buffer</li>
<li>The application writes the data back into kernel space into a socket buffer</li>
<li>The operating system copies the data from the socket buffer to the NIC buffer where it is sent over the network</li>
</ol>
<p><strong>Unix sendfile optimization (zero-copy optimization)</strong>: disk -&gt; pagecache -&gt; socket</p>
<p>This could be reused for many consumers without copying many times</p>
<h4 id="end-to-end-batch-compression">End-to-End Batch Compression</h4>
<p>Efficient compression requires compressing multiple messages together rather than compressing each message individually.<br>
Kafka supports this with an efficient batching format. A batch of messages can be grouped together, compressed, and sent to the server in this form. The <strong>broker decompresses</strong> the batch in order to <strong>validate</strong> it. For example, it validates that the number of records in the batch is same as what batch header states. This batch of messages is then <strong>written to disk</strong> in compressed form. The batch will remain <strong>compressed in the log</strong> and it will also be <strong>transmitted to the consumer in compressed form</strong>. The <strong>consumer decompresses</strong> any compressed data that it receives</p>
<h3 id="the-producer-design">The Producer design</h3>
<p>producer send directly to the broker w/o intervening routing tier (中间路由层)<br>
-&gt; thus all Kafka nodes should have the ability to answer request of which<br>
servers are alive</p>
<p>Client (producer) control which partition to publish, it can be random (load<br>
balancing) or semantic (allow user to specify a key for partition operation,<br>
which is usually a hash func).</p>
<p>This will allow user to locally assume their consumptions (controllable and<br>
predictable)</p>
<p><strong>Asychronous Send</strong>: with batching, the sender needs to buffer send data to<br>
certain size before eventually sending them out, which requires asynchronous<br>
send.</p>
<h3 id="the-consumer-design">The Consumer design</h3>
<p>works by issuing “fetch” requests to the brokers leading the partitions it wants to consume</p>
<p>fetch operation includes an offset of the log, and will receive chunk of log<br>
after that offset.</p>
<h4 id="broker-push-vs-consumer-pull">(Broker) Push vs. (Consumer) Pull</h4>
<p><strong>Pros</strong>:</p>
<ol>
<li><strong>Controllable Rate</strong>: The goal (for consumer pull method) is generally for the consumer to be able to consume at the maximum possible rate, namely for broker push method the centric broker will send downstream data at its rate but not considering real consumer rate.</li>
<li><strong>Batching Supporting</strong>: For broker push, if immediately it will cause poor<br>
batching (waste bandwidth), if buffer for sometime, broker itself does not<br>
know when this data will be in fact consumed by the consumer (might buffer up a<br>
lot of unconsumed data at consumer side); For consumer pull, it will always pull<br>
all the buffered (batch) data at broker side.</li>
</ol>
<p><strong>Cons</strong>:</p>
<ol>
<li>if the broker has no data the consumer may end up polling in a tight loop, effectively busy-waiting for data to arrive.<br>
<strong>Solution</strong>: allow the consumer request to block in a “long poll” waiting until data arrives</li>
</ol>
<h4 id="consumer-position">Consumer Position</h4>
<p>Keeping track of what has been consumed is one of the key performance points of a messaging system.</p>
<p>For traditional brokers, if certain data is fetched by one consumer, broker will<br>
either <strong>records that fact locally immediately</strong> or <strong>wait for acknowledgement<br>
from the consumer</strong>. But this could have <strong>consistency</strong> problems.</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Send -&gt; Network -&gt; Received</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>In these 3 steps all might faile, and leads to the problems discussed in eecs482<br>
(at-least-once, at-most-once, exactly-once).</p>
<p>Our topic is divided into a set of <strong>totally ordered partitions</strong>, each of which is consumed by exactly one consumer within each subscribing consumer group at any given time -&gt; the position of a consumer in each partition is just a <strong>single integer</strong>, the offset of the next message to consume.</p>
<p>Pros:</p>
<ul>
<li>This makes the state about what has been consumed very small, just one number for each partition.</li>
<li>This state can be periodically checkpointed.</li>
<li>This makes the equivalent of message acknowledgements very cheap.</li>
<li>A consumer can deliberately rewind back to an old offset and re-consume data. This violates the common contract of a queue, but turns out to be an essential feature for many consumers</li>
</ul>
<h4 id="offline-data-load-re-check-this-after-reading-the-hadoop">Offline Data Load (Re-check this after reading the Hadoop)</h4>
<p>Scalable persistence allows for the possibility of consumers that only periodically consume such as batch data loads that periodically bulk-load data into an offline system such as Hadoop or a relational data warehouse.</p>
<h4 id="static-membership">Static Membership</h4>
<p><strong>Aim</strong>: improve the availability of stream applications, consumer groups and other applications built on top of the group rebalance protocol</p>
<p>For dynamic members, when it restart, it will be assigned an entity id, but for<br>
a static member, its id will be kept</p>
<h3 id="message-delivery-semantics">Message Delivery Semantics</h3>
<p>As discussed many times above, semantics are following 3:</p>
<ul>
<li>At-least-once
<ul>
<li>the problem is that the consumer may receive the same message more than<br>
once, and the solution is to assign each message a <strong>unique id</strong> and the consumer</li>
<li>another solution is to use <strong>transaction log</strong></li>
</ul>
</li>
<li>At-most-once
<ul>
<li>consumer when reading msgs, it first write to the log and then process to<br>
the output</li>
<li>if crash happens btw log finished and the processing, then the msg will be considered finished but in fact not.</li>
</ul>
</li>
<li>Exactly-once</li>
</ul>
<p><strong>producer</strong> could specify the <strong>level of durability</strong>, and that it wants to perform the <strong>send completely asynchronously</strong> or that it wants to <strong>wait only until the leader (but not necessarily the followers) have the message</strong>.</p>
<p><strong>consumer</strong>:</p>
<ol>
<li>save-pos-then-process: described above in the at-most-once part</li>
<li>process-then-save-pos: the consumer will first process the message and then save the position of the last message it has processed, result is similar to the at-least-once part above.</li>
</ol>
<h4 id="kafka-stream">Kafka Stream</h4>
<p>Kafka Streams ensure that all of the messages are processed exactly-once</p>
<p>namely we send the <strong>output topic with the same key</strong> as the input topic, this<br>
is called <strong>Two-Phase Commit</strong>.</p>
<ul>
<li>commit successful: process output is visible, next time poll next unprocessed<br>
node.</li>
<li>abort: process output is not visible, next time poll the same node, since the<br>
transaction is not updated as well.</li>
</ul>
<p>The remaining problem is that in external systems (not follow Kafka protocol), the position and the process output may be stored in different places. This can be handled more simply and generally by letting the consumer store its offset in the same place as its output.</p>
<h3 id="kafka-transaction">Kafka Transaction</h3>
<p>In Kafka, only producers are transactional, and they are able to make transactional updates to the consumer’s position (confusingly called the “committed offset”), and it is this which gives the overall exactly-once behavior.</p>
<p>There are three key aspects to exactly-once processing using the producer and consumer, which match how Kafka Streams works.</p>
<ol>
<li>The consumer uses partition assignment to ensure that it is the only consumer in the consumer group currently processing each partition.</li>
<li>The producer uses transactions so that all the records it produces, and any offsets it updates on behalf of the consumer (the brokers will record the consumer’s offset in it), are performed atomically</li>
<li>In order to handle transactions properly in combination with rebalancing, it is advisable to use one producer instance for each consumer instance. More complicated and efficient schemes are possible, but at the cost of greater complexity.</li>
</ol>
<h3 id="kafka-replication">Kafka Replication</h3>
<p>Kafka allows topic partion to have multiple replicas, which can be configured at<br>
server</p>
<p>If some nodes in the cluster fails, the structure could move the data<br>
<strong>automatically</strong>, which esure the reliablity of the system.</p>
<h4 id="leader-and-follower">Leader and Follower</h4>
<p>The unit for replica is <strong>topic’s partition</strong>, and each partition has <strong>one leader</strong> and <strong>multiple follower replicas</strong>.</p>
<p>total number of replicas = 1 leader + N followers</p>
<p>Usually, # of partion &gt;&gt; # of brokers, each partion’s leader will be distributed<br>
evenly among brokers</p>
<p>All follower nodes will sync leader node’s logs, where the notes and offsets<br>
coinsides with the leader node’s logs.</p>
<p>Followers consume messages from the leader just as a normal Kafka consumer<br>
would and apply them to their own log. Follower nodes could pull batch logs from<br>
their leader.</p>
<p><strong>How to define that a node is <em>alive</em>?</strong> (the precise definition of alive is<br>
required by automatically handling failures process)</p>
<ul>
<li>brokers must <strong>maintain an active session with the controller</strong> in order to<br>
receive regular metadata updates.</li>
<li>brokers acting as <strong>followers</strong> must <strong>replicate the writes</strong> from the leader and not<br>
fall “too far” behind. (<strong>Close Following</strong>)</li>
</ul>
<p>we refer to nodes satisfying these two conditions as being <strong>“in sync”</strong> (not<br>
alive or failed). Ther <strong>leader keeps track of</strong> the set of “in sync” <strong>replicas (set of In Sync Replica = ISR)</strong><br>
If any replicas failed to meet either condition, leader will remove them from<br>
ISR</p>
<p><strong>Failure Types in Distributed System</strong>: the failures we will try to solve in<br>
distributed system is kind of “fail/recover” style, where any node stop<br>
workingsuddenly and then recover (not failing forever). We do not aim to solve<br>
“<strong>Byzantine</strong>” style failures, namely when one node encounters random(malformed) responses</p>
<p><strong>Presice Definition of Commit</strong>: only after all messages’ replicas are added to<br>
the log can be assumed committed. And only Commited messages are gonna being consumed. With this restriction, we don’t need to worry about if the leader failed.</p>
<h4 id="replication-logs-quorums-isrs-and-state-machines">Replication logs: Quorums, ISRs, and State Machines</h4>
<p>replicated log is the heart of Kafka.</p>
<p>A replicated log can be used by other systems as a primitive for implementing<br>
other distributed system in the <strong>state-machine style</strong>.</p>
<p>Relicated log models with a series of ordered value. The simplest method is by<br>
<strong>leader node</strong> provide to choose the required value, as long as the leader node is<br>
alive. All follower only need to copy the replicas data and orders as the leader</p>
<p>If leader crashes, we need to pick one leadr from the follower, but the problem<br>
is that followers might fall behind or crash itself. So we need to make sure<br>
that our leader “candidates”  are  in sync follower with latest data.</p>
<p><strong>Quorum</strong>: when writing data we need to make sure that a number of replicas are<br>
writen successfully, while when reading data we need to make sure that a number<br>
of replicas are read successfully. If you choose the number of acknowledgements required and the number of logs that must be compared to elect a leader such that there is <strong>guaranteed to be an overlap</strong>, then this is called a Quorum.<br>
To be short, quorum-based strategy means that there must be <strong>at least k</strong><br>
replicas to be considered successful.</p>
<p><strong>Majority Vote</strong>: If there are 2f+1 replicas and at least f+1 replicas received<br>
the latest msg, then if failure of leader happens, we can have f+1 machine, at<br>
least one replica in them are in sync, and thus we could find a good one to<br>
become the next leader.<br>
<strong>Advantage of MV</strong>: latency depends on the fastest server, if the replica index<br>
= 3, then f+1 = 2, namely we need 2 fastest replicas to be in sync (1 faster<br>
follower)<br>
<strong>Disadvantage of MV</strong>: if many nodes fail, then it could be difficult to find<br>
an electable leader. To tolerate 1 failure, we need 2f+1 = 3 replicas, but if 2<br>
failures, then we need 5 replicas, and so on. This is not a good solution for<br>
high bandwidth and disk space.</p>
<p><strong>Kafka’s Design on Replica</strong>: Kafka dynamically maintains a ISR, where nodes in<br>
the ISR are all highly synced with the leader. Only ISR members are qualified<br>
for the leader, and any mst should be appded to the logs of any nodes in ISR,<br>
and then the message could be commited. (ISR not include all the replicas, but<br>
must include a user-specified number of replicas, and a replica following too<br>
slow will be temporarily removed from the ISR and will be added to later if its<br>
catches up with the leader). The ISR model will tolerate up to f failures when there<br>
are f+1 replicas, thus this is called <strong>f+1 model</strong>.</p>
<p>This can be considered as the <strong>tradeoff</strong> between the efficiency and the<br>
consistency.</p>
<p>Another important design difference is that, Kafka will not require the failure<br>
node to recover all its data (with <code>fsync</code>), but if a failed-and-recovered node<br>
wants to be back to ISR, it needs to replay the logs (by pulling logs from the<br>
leader)</p>
<h4 id="unclean-leader-election-what-if-all-nodes-are-down">Unclean Leader Election: what if all nodes are down?</h4>
<p>2 ways to solve if all replicas are failed:</p>
<ol>
<li>wait for one ISR replica to recover to working state, and choose ths replica<br>
to be the leader.</li>
<li>Choose any first node that recovers (not necessarily in the ISR) as the<br>
leader.</li>
</ol>
<p>This is a <strong>tradeoff</strong> between the <strong>availability</strong> and the <strong>consistency</strong>.<br>
If we choose the first method, then there will be long downtime for the first<br>
recovered ISR node;<br>
If we choose the second method, it might be unconsistent.<br>
Kafka chooses the <strong>second</strong> method by default.</p>
<h4 id="availablity-vs-consistency">Availablity vs. Consistency</h4>
<p>when writing to Kafka, producer set <code>ack</code> to check the commit state: <code>ack = 0</code><br>
means that is does not wait for broker’s acknowledgement; <code>ack = 1</code> meas that it<br>
waits for leader to successfully commited; <code>ack = -1 (all)</code> means that it waits for all replicas in the ISR to be commited.</p>
<p>We could set the consistency level by following methods:</p>
<ol>
<li>disable unclean leader election: only wait for the latest leader to recover</li>
<li>set the minimum size of hte ISR</li>
</ol>
<h4 id="replica-management">Replica Management</h4>
<p>Since the above replication strategy is within range of one topic’s one partion,<br>
and a kafka cluster has millions of such partitions, and the failure happens on<br>
the granularity of a broker (set of partitions), thus the kafka manager should<br>
do such as <strong>load-balancing</strong> to balance the partition load within the cluster,<br>
to avoid that most partitions focuses on few nodes. Also the leadership should<br>
be balanced to make every node be some partition’s leader node.</p>
<h3 id="log-compaction-日志压缩">Log Compaction (日志压缩)</h3>
<p>Logs in the system can be grown to very large even if the data set itself is<br>
small. Since the tiem is inifinite, small data set’s logs could grow gradually<br>
and finally become a very large one. This is the motivation of log compaction:<br>
we need to abandon some “useless” logs to save space.</p>
<p>What is useless logs? Logs are used for failure recovery where user might try to<br>
replay the logged operations and rebuild the state of the system. Traditional method is to abandon logs after several time threshold (<strong>time-scaled</strong>), yet this could be slow on restart, since a single value may be modified many times, but most of the time we need the <strong>final state</strong> of certain variable.</p>
<p>Here comes how we do the log compaction: According to the key (it’s like the<br>
database system where all data entries are key-value pairs), we will update the<br>
key in the log (overwrite). And the result is that we only maintain a set of<br>
active keys in the log with their final states, and at the same time the total<br>
disk usage is reduced.</p>
<h4 id="how-to-achieve-log-compaction">How to Achieve Log Compaction</h4>
<p>The following is a high level log-logic figure, which shows the logic structure<br>
of each message’s offset structure in Kafka log.</p>
<p><img src="/images/log_cleaner_anatomy.png" alt="log_cleaner_anatomy"></p>
<p><strong>Log Head</strong>: includes the traditional Kafka logs, which includes the continuous<br>
offset and all messages. Log compaction add options to handle tail logs.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://example.com">Yuchen You (Wesley)</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://example.com/2025/05/07/wesley_knowledge_repo/os/Apache/1.%20Kafka/">http://example.com/2025/05/07/wesley_knowledge_repo/os/Apache/1.%20Kafka/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/distributed-sys/">distributed_sys</a></div><div class="post_share"><div class="social-share" data-image="/img/me_new.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/05/08/wesley_knowledge_repo/os/mit_cs824/2.%20The%20Design%20of%20a%20Practical%20System%20for%20Fault-Tolerant%20Virtual%20Machines/" title="2. The Design of a Practical System for Fault-Tolerant Virtual Machines"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">2. The Design of a Practical System for Fault-Tolerant Virtual Machines</div></div></a></div><div class="next-post pull-right"><a href="/2025/05/07/wesley_knowledge_repo/os/mit_cs824/1.%20MapReduce,%20Simplified%20Data%20Processing%20on%20Large%20Clusters/" title="1. Map Reduce, Simplified Data Processing on Large Clusters"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next</div><div class="next_info">1. Map Reduce, Simplified Data Processing on Large Clusters</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2025/05/07/wesley_knowledge_repo/os/mit_cs824/1.%20MapReduce,%20Simplified%20Data%20Processing%20on%20Large%20Clusters/" title="1. Map Reduce, Simplified Data Processing on Large Clusters"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-07</div><div class="title">1. Map Reduce, Simplified Data Processing on Large Clusters</div></div></a></div><div><a href="/2025/05/08/wesley_knowledge_repo/os/mit_cs824/2.%20The%20Design%20of%20a%20Practical%20System%20for%20Fault-Tolerant%20Virtual%20Machines/" title="2. The Design of a Practical System for Fault-Tolerant Virtual Machines"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-09</div><div class="title">2. The Design of a Practical System for Fault-Tolerant Virtual Machines</div></div></a></div><div><a href="/2025/05/10/wesley_knowledge_repo/os/mit_cs824/0.%20Hadoop%20Distributed%20File%20System/" title="0. Hadoop Distributed File System"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-10</div><div class="title">0. Hadoop Distributed File System</div></div></a></div><div><a href="/2025/05/13/wesley_knowledge_repo/os/OrderLab/2.%20Predictive%20and%20Adaptive%20Failure%20Mitigation%20to%20Avert%20Production%20Cloud%20VM%20Interruptions/" title="2. Predictive and Adaptive Failure Mitigation to Avert Production Cloud VM Interruptions"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-13</div><div class="title">2. Predictive and Adaptive Failure Mitigation to Avert Production Cloud VM Interruptions</div></div></a></div><div><a href="/2025/05/12/wesley_knowledge_repo/os/OrderLab/1.%20AIOpsLab%20A%20Holistic%20Framework%20to%20Evaluate%20AI%20Agents%20for%20Enabling%20Autonomous%20Clouds/" title="1. AIOpsLab: A Holistic Framework to Evaluate AI Agents for Enabling Autonomous Clouds"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-12</div><div class="title">1. AIOpsLab: A Holistic Framework to Evaluate AI Agents for Enabling Autonomous Clouds</div></div></a></div><div><a href="/2025/05/22/wesley_knowledge_repo/os/OrderLab/3.%20Metastable%20Failures%20in%20Distributed%20Systems/" title="3. Metastable Failures in Distributed Systems"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-22</div><div class="title">3. Metastable Failures in Distributed Systems</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/me_new.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Yuchen You (Wesley)</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">293</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/1WesleyYou"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/1Wesleyyou" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:yuchenxr@umich.edu" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://www.linkedin.com/in/yuchen-you-a74940314/?locale=en_US" target="_blank" title="LinkedIn"><i class="fab fa-linkedin" style="color: #4a4dbe;"></i></a><a class="social-icon" href="/Resume.pdf" target="_blank" title="CV"><i class="fas fa-address-card" style="color: #251456;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#event-streaming"><span class="toc-number">1.1.</span> <span class="toc-text">Event Streaming</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka-s-event-stream-purpose"><span class="toc-number">1.2.</span> <span class="toc-text">Kafka’s Event Stream Purpose</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#server-and-client-in-kafka"><span class="toc-number">1.3.</span> <span class="toc-text">Server and Client in Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#server"><span class="toc-number">1.3.1.</span> <span class="toc-text">Server</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#client"><span class="toc-number">1.3.2.</span> <span class="toc-text">Client</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">1.4.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">1.5.</span> <span class="toc-text">应用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#messaging-%E6%B6%88%E6%81%AF%E4%BB%A3%E7%90%86"><span class="toc-number">1.5.1.</span> <span class="toc-text">Messaging 消息代理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#website-activity-tracking"><span class="toc-number">1.5.2.</span> <span class="toc-text">Website Activity Tracking</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#design"><span class="toc-number">2.</span> <span class="toc-text">Design</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#motivation"><span class="toc-number">2.1.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#persistence"><span class="toc-number">2.2.</span> <span class="toc-text">Persistence</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#pagecache-%E9%A1%B5%E7%BC%93%E5%AD%98-recall-memory-is-the-unified-cache-for-address-space"><span class="toc-number">2.2.1.</span> <span class="toc-text">PageCache 页缓存 (recall memory is the unified cache for address space)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pagecache-centric"><span class="toc-number">2.2.2.</span> <span class="toc-text">PageCache-Centric</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#constant-time-suffies"><span class="toc-number">2.3.</span> <span class="toc-text">Constant Time Suffies</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#log-structure-append-only-commit-log"><span class="toc-number">2.3.1.</span> <span class="toc-text">Log Structure (Append-Only-Commit-Log)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#efficiency"><span class="toc-number">2.4.</span> <span class="toc-text">Efficiency</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#address-the-too-many-small-io-operations-batching"><span class="toc-number">2.4.1.</span> <span class="toc-text">Address the “Too many small IO operations”: Batching</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#address-the-excessive-byte-copying"><span class="toc-number">2.4.2.</span> <span class="toc-text">Address the “Excessive byte copying”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#end-to-end-batch-compression"><span class="toc-number">2.4.3.</span> <span class="toc-text">End-to-End Batch Compression</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-producer-design"><span class="toc-number">2.5.</span> <span class="toc-text">The Producer design</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-consumer-design"><span class="toc-number">2.6.</span> <span class="toc-text">The Consumer design</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#broker-push-vs-consumer-pull"><span class="toc-number">2.6.1.</span> <span class="toc-text">(Broker) Push vs. (Consumer) Pull</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#consumer-position"><span class="toc-number">2.6.2.</span> <span class="toc-text">Consumer Position</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#offline-data-load-re-check-this-after-reading-the-hadoop"><span class="toc-number">2.6.3.</span> <span class="toc-text">Offline Data Load (Re-check this after reading the Hadoop)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#static-membership"><span class="toc-number">2.6.4.</span> <span class="toc-text">Static Membership</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#message-delivery-semantics"><span class="toc-number">2.7.</span> <span class="toc-text">Message Delivery Semantics</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#kafka-stream"><span class="toc-number">2.7.1.</span> <span class="toc-text">Kafka Stream</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka-transaction"><span class="toc-number">2.8.</span> <span class="toc-text">Kafka Transaction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka-replication"><span class="toc-number">2.9.</span> <span class="toc-text">Kafka Replication</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#leader-and-follower"><span class="toc-number">2.9.1.</span> <span class="toc-text">Leader and Follower</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#replication-logs-quorums-isrs-and-state-machines"><span class="toc-number">2.9.2.</span> <span class="toc-text">Replication logs: Quorums, ISRs, and State Machines</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#unclean-leader-election-what-if-all-nodes-are-down"><span class="toc-number">2.9.3.</span> <span class="toc-text">Unclean Leader Election: what if all nodes are down?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#availablity-vs-consistency"><span class="toc-number">2.9.4.</span> <span class="toc-text">Availablity vs. Consistency</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#replica-management"><span class="toc-number">2.9.5.</span> <span class="toc-text">Replica Management</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#log-compaction-%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9"><span class="toc-number">2.10.</span> <span class="toc-text">Log Compaction (日志压缩)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#how-to-achieve-log-compaction"><span class="toc-number">2.10.1.</span> <span class="toc-text">How to Achieve Log Compaction</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/02/wesley_knowledge_repo/db/3.normalization/" title="3. Normalization">3. Normalization</a><time datetime="2025-10-02T13:43:37.000Z" title="Created 2025-10-02 21:43:37">2025-10-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/01/wesley_knowledge_repo/os/historical/20.lottery_scheduling.md/" title="20. Lottery Scheduling: Flexible Proportional-Share Resource Management">20. Lottery Scheduling: Flexible Proportional-Share Resource Management</a><time datetime="2025-10-01T12:38:57.000Z" title="Created 2025-10-01 20:38:57">2025-10-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/30/wesley_knowledge_repo/os/historical/19.scheduler_activation/" title="19. Scheduler Activations: Effective Kernel Support  for the User-Level Management of Parallelism">19. Scheduler Activations: Effective Kernel Support  for the User-Level Management of Parallelism</a><time datetime="2025-09-30T13:23:07.000Z" title="Created 2025-09-30 21:23:07">2025-09-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/29/wesley_knowledge_repo/os/historical/18.vmware_esx_mem/" title="18.vmware_esx_mem">18.vmware_esx_mem</a><time datetime="2025-09-29T05:19:27.000Z" title="Created 2025-09-29 13:19:27">2025-09-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/28/wesley_knowledge_repo/os/historical/17.superpage/" title="17.superpage">17.superpage</a><time datetime="2025-09-28T08:35:17.000Z" title="Created 2025-09-28 16:35:17">2025-09-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Yuchen You (Wesley)</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">welcome to my blog!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>